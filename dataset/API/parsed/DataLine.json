{"name": "Interface DataLine", "module": "java.desktop", "package": "javax.sound.sampled", "text": "DataLine adds media-related functionality to its superinterface,\n Line. This functionality includes transport-control methods that\n start, stop, drain, and flush the audio data that passes through the line. A\n data line can also report the current position, volume, and audio format of\n the media. Data lines are used for output of audio by means of the\n subinterfaces SourceDataLine or Clip, which allow an\n application program to write data. Similarly, audio input is handled by the\n subinterface TargetDataLine, which allows data to be read.\n \n A data line has an internal buffer in which the incoming or outgoing audio\n data is queued. The drain() method blocks until this internal buffer\n becomes empty, usually because all queued data has been processed. The\n flush() method discards any available queued data from the internal\n buffer.\n \n A data line produces START and\n STOP events whenever it begins or ceases active\n presentation or capture of data. These events can be generated in response to\n specific requests, or as a result of less direct state changes. For example,\n if start() is called on an inactive data line, and data is available\n for capture or playback, a START event will be generated shortly,\n when data playback or capture actually begins. Or, if the flow of data to an\n active data line is constricted so that a gap occurs in the presentation of\n data, a STOP event is generated.\n \n Mixers often support synchronized control of multiple data lines.\n Synchronization can be established through the Mixer interface's\n synchronize method. See the description of the\n Mixer interface for a more complete description.", "codes": ["public interface DataLine\nextends Line"], "fields": [], "methods": [{"method_name": "drain", "method_sig": "void drain()", "description": "Drains queued data from the line by continuing data I/O until the data\n line's internal buffer has been emptied. This method blocks until the\n draining is complete. Because this is a blocking method, it should be\n used with care. If drain() is invoked on a stopped line that has\n data in its queue, the method will block until the line is running and\n the data queue becomes empty. If drain() is invoked by one\n thread, and another continues to fill the data queue, the operation will\n not complete. This method always returns when the data line is closed."}, {"method_name": "flush", "method_sig": "void flush()", "description": "Flushes queued data from the line. The flushed data is discarded. In some\n cases, not all queued data can be discarded. For example, a mixer can\n flush data from the buffer for a specific input line, but any unplayed\n data already in the output buffer (the result of the mix) will still be\n played. You can invoke this method after pausing a line (the normal case)\n if you want to skip the \"stale\" data when you restart playback or\n capture. (It is legal to flush a line that is not stopped, but doing so\n on an active line is likely to cause a discontinuity in the data,\n resulting in a perceptible click.)"}, {"method_name": "start", "method_sig": "void start()", "description": "Allows a line to engage in data I/O. If invoked on a line that is already\n running, this method does nothing. Unless the data in the buffer has been\n flushed, the line resumes I/O starting with the first frame that was\n unprocessed at the time the line was stopped. When audio capture or\n playback starts, a START event is generated."}, {"method_name": "stop", "method_sig": "void stop()", "description": "Stops the line. A stopped line should cease I/O activity. If the line is\n open and running, however, it should retain the resources required to\n resume activity. A stopped line should retain any audio data in its\n buffer instead of discarding it, so that upon resumption the I/O can\n continue where it left off, if possible. (This doesn't guarantee that\n there will never be discontinuities beyond the current buffer, of course;\n if the stopped condition continues for too long, input or output samples\n might be dropped.) If desired, the retained data can be discarded by\n invoking the flush method. When audio capture or playback stops,\n a STOP event is generated."}, {"method_name": "isRunning", "method_sig": "boolean isRunning()", "description": "Indicates whether the line is running. The default is false. An\n open line begins running when the first data is presented in response to\n an invocation of the start method, and continues until\n presentation ceases in response to a call to stop or because\n playback completes."}, {"method_name": "isActive", "method_sig": "boolean isActive()", "description": "Indicates whether the line is engaging in active I/O (such as playback or\n capture). When an inactive line becomes active, it sends a\n START event to its listeners. Similarly,\n when an active line becomes inactive, it sends a\n STOP event."}, {"method_name": "getFormat", "method_sig": "AudioFormat getFormat()", "description": "Obtains the current format (encoding, sample rate, number of channels,\n etc.) of the data line's audio data.\n \n If the line is not open and has never been opened, it returns the default\n format. The default format is an implementation specific audio format,\n or, if the DataLine.Info object, which was used to retrieve this\n DataLine, specifies at least one fully qualified audio format,\n the last one will be used as the default format. Opening the line with a\n specific audio format (e.g. SourceDataLine.open(AudioFormat))\n will override the default format."}, {"method_name": "getBufferSize", "method_sig": "int getBufferSize()", "description": "Obtains the maximum number of bytes of data that will fit in the data\n line's internal buffer. For a source data line, this is the size of the\n buffer to which data can be written. For a target data line, it is the\n size of the buffer from which data can be read. Note that the units used\n are bytes, but will always correspond to an integral number of sample\n frames of audio data."}, {"method_name": "available", "method_sig": "int available()", "description": "Obtains the number of bytes of data currently available to the\n application for processing in the data line's internal buffer. For a\n source data line, this is the amount of data that can be written to the\n buffer without blocking. For a target data line, this is the amount of\n data available to be read by the application. For a clip, this value is\n always 0 because the audio data is loaded into the buffer when the clip\n is opened, and persists without modification until the clip is closed.\n \n Note that the units used are bytes, but will always correspond to an\n integral number of sample frames of audio data.\n \n An application is guaranteed that a read or write operation of up to the\n number of bytes returned from available() will not block;\n however, there is no guarantee that attempts to read or write more data\n will block."}, {"method_name": "getFramePosition", "method_sig": "int getFramePosition()", "description": "Obtains the current position in the audio data, in sample frames. The\n frame position measures the number of sample frames captured by, or\n rendered from, the line since it was opened. This return value will wrap\n around after 2^31 frames. It is recommended to use\n getLongFramePosition instead."}, {"method_name": "getLongFramePosition", "method_sig": "long getLongFramePosition()", "description": "Obtains the current position in the audio data, in sample frames. The\n frame position measures the number of sample frames captured by, or\n rendered from, the line since it was opened."}, {"method_name": "getMicrosecondPosition", "method_sig": "long getMicrosecondPosition()", "description": "Obtains the current position in the audio data, in microseconds. The\n microsecond position measures the time corresponding to the number of\n sample frames captured by, or rendered from, the line since it was\n opened. The level of precision is not guaranteed. For example, an\n implementation might calculate the microsecond position from the current\n frame position and the audio sample frame rate. The precision in\n microseconds would then be limited to the number of microseconds per\n sample frame."}, {"method_name": "getLevel", "method_sig": "float getLevel()", "description": "Obtains the current volume level for the line. This level is a measure of\n the signal's current amplitude, and should not be confused with the\n current setting of a gain control. The range is from 0.0 (silence) to 1.0\n (maximum possible amplitude for the sound waveform). The units measure\n linear amplitude, not decibels."}]}