{"name": "Class AudioFormat", "module": "java.desktop", "package": "javax.sound.sampled", "text": "AudioFormat is the class that specifies a particular arrangement of\n data in a sound stream. By examining the information stored in the audio\n format, you can discover how to interpret the bits in the binary sound data.\n \n Every data line has an audio format associated with its data stream. The\n audio format of a source (playback) data line indicates what kind of data the\n data line expects to receive for output. For a target (capture) data line,\n the audio format specifies the kind of the data that can be read from the\n line.\n \n Sound files also have audio formats, of course. The AudioFileFormat\n class encapsulates an AudioFormat in addition to other, file-specific\n information. Similarly, an AudioInputStream has an\n AudioFormat.\n \n The AudioFormat class accommodates a number of common sound-file\n encoding techniques, including pulse-code modulation (PCM), mu-law encoding,\n and a-law encoding. These encoding techniques are predefined, but service\n providers can create new encoding types. The encoding that a specific format\n uses is named by its encoding field.\n \n In addition to the encoding, the audio format includes other properties that\n further specify the exact arrangement of the data. These include the number\n of channels, sample rate, sample size, byte order, frame rate, and frame\n size. Sounds may have different numbers of audio channels: one for mono, two\n for stereo. The sample rate measures how many \"snapshots\" (samples) of the\n sound pressure are taken per second, per channel. (If the sound is stereo\n rather than mono, two samples are actually measured at each instant of time:\n one for the left channel, and another for the right channel; however, the\n sample rate still measures the number per channel, so the rate is the same\n regardless of the number of channels. This is the standard use of the term.)\n The sample size indicates how many bits are used to store each snapshot; 8\n and 16 are typical values. For 16-bit samples (or any other sample size\n larger than a byte), byte order is important; the bytes in each sample are\n arranged in either the \"little-endian\" or \"big-endian\" style. For encodings\n like PCM, a frame consists of the set of samples for all channels at a given\n point in time, and so the size of a frame (in bytes) is always equal to the\n size of a sample (in bytes) times the number of channels. However, with some\n other sorts of encodings a frame can contain a bundle of compressed data for\n a whole series of samples, as well as additional, non-sample data. For such\n encodings, the sample rate and sample size refer to the data after it is\n decoded into PCM, and so they are completely different from the frame rate\n and frame size.\n \n An AudioFormat object can include a set of properties. A property is\n a pair of key and value: the key is of type String, the associated\n property value is an arbitrary object. Properties specify additional format\n specifications, like the bit rate for compressed formats. Properties are\n mainly used as a means to transport additional information of the audio\n format to and from the service providers. Therefore, properties are ignored\n in the matches(AudioFormat) method. However, methods which rely on\n the installed service providers, like\n (AudioFormat, AudioFormat)\n isConversionSupported may consider properties, depending on the respective\n service provider implementation.\n \n The following table lists some common properties which service providers\n should use, if applicable:\n\n \nAudio Format Properties\n\n\nProperty key\n     Value type\n     Description\n \n\n\n\"bitrate\"\n     Integer\naverage bit rate in bits per second\n   \n\"vbr\"\n     Boolean\ntrue, if the file is encoded in variable bit rate (VBR)\n   \n\"quality\"\n     Integer\nencoding/conversion quality, 1..100\n \n\n\n Vendors of service providers (plugins) are encouraged to seek information\n about other already established properties in third party plugins, and follow\n the same conventions.", "codes": ["public class AudioFormat\nextends Object"], "fields": [{"field_name": "encoding", "field_sig": "protected\u00a0AudioFormat.Encoding encoding", "description": "The audio encoding technique used by this format."}, {"field_name": "sampleRate", "field_sig": "protected\u00a0float sampleRate", "description": "The number of samples played or recorded per second, for sounds that have\n this format."}, {"field_name": "sampleSizeInBits", "field_sig": "protected\u00a0int sampleSizeInBits", "description": "The number of bits in each sample of a sound that has this format."}, {"field_name": "channels", "field_sig": "protected\u00a0int channels", "description": "The number of audio channels in this format (1 for mono, 2 for stereo)."}, {"field_name": "frameSize", "field_sig": "protected\u00a0int frameSize", "description": "The number of bytes in each frame of a sound that has this format."}, {"field_name": "frameRate", "field_sig": "protected\u00a0float frameRate", "description": "The number of frames played or recorded per second, for sounds that have\n this format."}, {"field_name": "bigEndian", "field_sig": "protected\u00a0boolean bigEndian", "description": "Indicates whether the audio data is stored in big-endian or little-endian\n order."}], "methods": [{"method_name": "getEncoding", "method_sig": "public AudioFormat.Encoding getEncoding()", "description": "Obtains the type of encoding for sounds in this format."}, {"method_name": "getSampleRate", "method_sig": "public float getSampleRate()", "description": "Obtains the sample rate. For compressed formats, the return value is the\n sample rate of the uncompressed audio data. When this AudioFormat\n is used for queries (e.g.\n AudioSystem.isConversionSupported) or capabilities (e.g.\n DataLine.Info.getFormats), a sample rate\n of AudioSystem.NOT_SPECIFIED means that any sample rate is\n acceptable. AudioSystem.NOT_SPECIFIED is also returned when the\n sample rate is not defined for this audio format."}, {"method_name": "getSampleSizeInBits", "method_sig": "public int getSampleSizeInBits()", "description": "Obtains the size of a sample. For compressed formats, the return value is\n the sample size of the uncompressed audio data. When this\n AudioFormat is used for queries (e.g.\n AudioSystem.isConversionSupported) or capabilities (e.g.\n DataLine.Info.getFormats), a sample size\n of AudioSystem.NOT_SPECIFIED means that any sample size is\n acceptable. AudioSystem.NOT_SPECIFIED is also returned when the\n sample size is not defined for this audio format."}, {"method_name": "getChannels", "method_sig": "public int getChannels()", "description": "Obtains the number of channels. When this AudioFormat is used for\n queries (e.g. AudioSystem.isConversionSupported) or capabilities (e.g.\n DataLine.Info.getFormats), a return\n value of AudioSystem.NOT_SPECIFIED means that any (positive)\n number of channels is acceptable."}, {"method_name": "getFrameSize", "method_sig": "public int getFrameSize()", "description": "Obtains the frame size in bytes. When this AudioFormat is used\n for queries (e.g. AudioSystem.isConversionSupported) or capabilities (e.g.\n DataLine.Info.getFormats), a frame size\n of AudioSystem.NOT_SPECIFIED means that any frame size is\n acceptable. AudioSystem.NOT_SPECIFIED is also returned when the\n frame size is not defined for this audio format."}, {"method_name": "getFrameRate", "method_sig": "public float getFrameRate()", "description": "Obtains the frame rate in frames per second. When this\n AudioFormat is used for queries (e.g.\n AudioSystem.isConversionSupported) or capabilities (e.g.\n DataLine.Info.getFormats), a frame rate\n of AudioSystem.NOT_SPECIFIED means that any frame rate is\n acceptable. AudioSystem.NOT_SPECIFIED is also returned when the\n frame rate is not defined for this audio format."}, {"method_name": "isBigEndian", "method_sig": "public boolean isBigEndian()", "description": "Indicates whether the audio data is stored in big-endian or little-endian\n byte order. If the sample size is not more than one byte, the return\n value is irrelevant."}, {"method_name": "properties", "method_sig": "public Map<String, Object> properties()", "description": "Obtain an unmodifiable map of properties. The concept of properties is\n further explained in the class description."}, {"method_name": "getProperty", "method_sig": "public Object getProperty (String key)", "description": "Obtain the property value specified by the key. The concept of properties\n is further explained in the class description.\n \n If the specified property is not defined for a particular file format,\n this method returns null."}, {"method_name": "matches", "method_sig": "public boolean matches (AudioFormat format)", "description": "Indicates whether this format matches the one specified. To match, two\n formats must have the same encoding, and consistent values of the number\n of channels, sample rate, sample size, frame rate, and frame size. The\n values of the property are consistent if they are equal or the specified\n format has the property value AudioSystem.NOT_SPECIFIED. The byte\n order (big-endian or little-endian) must be the same if the sample size\n is greater than one byte."}, {"method_name": "toString", "method_sig": "public String toString()", "description": "Returns a string that describes the format, such as: \"PCM SIGNED 22050 Hz\n 16 bit mono big-endian\". The contents of the string may vary between\n implementations of Java Sound."}]}